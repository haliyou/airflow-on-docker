{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6676a3c3-b896-4ffc-a571-bb1f91908157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://d292e0a8628f:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark_commnicate_with_postgre</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6721663af0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "import os\n",
    "\n",
    "spark=pyspark.sql.SparkSession.builder.appName(\"pyspark_commnicate_with_postgre\")\\\n",
    ".config('spark.driver.extraClassPath', \"/home/jovyan/work/postgresql-42.4.0.jar\")\\\n",
    ".config('spark.executor.extraClassPath',\"/home/jovyan/work/postgresql-42.4.0.jar\")\\\n",
    ".getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebeb3158-ca0e-4ea7-ab7d-580e506ffc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read roles table from db using spark jdbc\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_CLASSPATH\"] = \"/home/jovyan/work/postgresql-42.4.0.jar\"\n",
    "airflow_df = spark.read.format(\"jdbc\")\\\n",
    ".option(\"url\",\"jdbc:postgresql://172.17.0.3:5432/postgres\")\\\n",
    ".option(\"dbtable\",\"roles\")\\\n",
    ".option(\"user\",\"postgres\")\\\n",
    ".option(\"password\",\"airflow\")\\\n",
    ".option(\"driver\",\"org.postgresql.Driver\")\\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19ec66cb-705f-4a5c-8665-3a6ab5af196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|role_id|role_name|\n",
      "+-------+---------+\n",
      "|      1|    admin|\n",
      "+-------+---------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(airflow_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f584acc-dde1-45ae-95e7-2d5ca4c56b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read account table from db using spark jdbc\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_CLASSPATH\"] = \"/home/jovyan/work/postgresql-42.4.0.jar\"\n",
    "accounts_df = spark.read.format(\"jdbc\")\\\n",
    ".option(\"url\",\"jdbc:postgresql://172.17.0.3:5432/postgres\")\\\n",
    ".option(\"dbtable\",\"accounts\")\\\n",
    ".option(\"user\",\"postgres\")\\\n",
    ".option(\"password\",\"airflow\")\\\n",
    ".option(\"driver\",\"org.postgresql.Driver\")\\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77b3e8ae-07ed-4b4f-9432-5cd31df1869e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------------------+-------------------+----------+\n",
      "|user_id|username| password|               email|         created_on|last_login|\n",
      "+-------+--------+---------+--------------------+-------------------+----------+\n",
      "|      1|   doyle|password1|doyle.wei.chen@gm...|2022-06-29 00:00:00|      null|\n",
      "+-------+--------+---------+--------------------+-------------------+----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(accounts_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfe6a9ab-6ff5-4d1e-babb-8e0a51bbf3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_role_join_df = airflow_df.join(accounts_df, airflow_df.role_id == accounts_df.user_id, 'left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "217c0b80-2e07-4cf1-8cbb-a5a904d82cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------+--------+---------+--------------------+-------------------+----------+\n",
      "|role_id|role_name|user_id|username| password|               email|         created_on|last_login|\n",
      "+-------+---------+-------+--------+---------+--------------------+-------------------+----------+\n",
      "|      1|    admin|      1|   doyle|password1|doyle.wei.chen@gm...|2022-06-29 00:00:00|      null|\n",
      "+-------+---------+-------+--------+---------+--------------------+-------------------+----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(account_role_join_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2044c14d-58d0-4058-a96f-08e8d9e1a817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------+--------+---------+--------------------+-------------------+----------+\n",
      "|role_id|role_name|user_id|username| password|               email|         created_on|last_login|\n",
      "+-------+---------+-------+--------+---------+--------------------+-------------------+----------+\n",
      "|      1|    admin|      1|   doyle|password1|doyle.wei.chen@gm...|2022-06-29 00:00:00|      null|\n",
      "+-------+---------+-------+--------+---------+--------------------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "account_role_join_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa73f8f1-2f34-4a1f-8b86-ac61c3ec1b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| role_name|\n",
      "+----------+\n",
      "|supervisor|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "role = [(\"supervisor\")]\n",
    "\n",
    "\n",
    "role_df = spark.createDataFrame([ Row(role_name='supervisor')])\n",
    "role_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "510f0f03-00d1-49c5-92ad-b3abca83b95d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view 'roles' already exists. SaveMode: ErrorIfExists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[43mrole_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjdbc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjdbc:postgresql://172.17.0.3:5432/postgres\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdbtable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgres\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mairflow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdriver\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morg.postgresql.Driver\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:738\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 738\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave(path)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view 'roles' already exists. SaveMode: ErrorIfExists."
     ]
    }
   ],
   "source": [
    "#overwrite and create and insert to a table if no foreign key involved\n",
    "role_df.select(\"role_name\").write.format(\"jdbc\")\\\n",
    ".option(\"url\",\"jdbc:postgresql://172.17.0.3:5432/postgres\")\\\n",
    ".option(\"dbtable\",\"roles\")\\\n",
    ".option(\"user\",\"postgres\")\\\n",
    ".option(\"password\",\"airflow\")\\\n",
    ".option(\"driver\",\"org.postgresql.Driver\")\\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14c6ae04-949e-48d3-b276-872b93b13985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append new row to existing table\n",
    "mode = \"append\"\n",
    "url =\"jdbc:postgresql://172.17.0.3:5432/postgres\"\n",
    "properties = {\"user\" :\"postgres\",\n",
    "              \"password\" : \"airflow\",\n",
    "              \"driver\" : \"org.postgresql.Driver\"\n",
    "             }\n",
    "role_df.write.jdbc(url = url,\n",
    "                   table = \"roles\",\n",
    "                   mode = mode,\n",
    "                   properties = properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26980b1c-e1bc-40cd-b624-8a45b8ee9faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|role_id| role_name|\n",
      "+-------+----------+\n",
      "|      1|     admin|\n",
      "|      2|supervisor|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airflow_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796025e-3b44-4312-a675-2f0d42e30451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
